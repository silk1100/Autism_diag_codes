{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from joblib import load\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMinMax:\n",
    "    def __init__(self, axis):\n",
    "        self.sc = MinMaxScaler()\n",
    "        self.axis = axis\n",
    "\n",
    "    def fit(self, X):\n",
    "        if self.axis==1:\n",
    "            self.sc = self.sc.fit(X.transpose())\n",
    "        elif self.axis==0:\n",
    "            self.sc = self.sc.fit(X)\n",
    "        return self.sc\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.axis==1:\n",
    "            Xn = self.sc.transform(X.transpose()).transpose()\n",
    "        elif self.axis==0:\n",
    "            Xn = self.sc.transform(X)\n",
    "        return Xn\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        if self.axis==1:\n",
    "            self.sc = self.sc.fit(X.transpose())\n",
    "            Xn = self.sc.transform(X.transpose()).transpose()\n",
    "        elif self.axis==0:\n",
    "            self.sc = self.sc.fit(X)\n",
    "            Xn = self.sc.transform(X)\n",
    "        return Xn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mynormalize(df, allfeats=False):\n",
    "    scalersdict = {}\n",
    "    if allfeats:\n",
    "        sc = MyMinMax(axis=1)\n",
    "        XN = sc.fit_transform(df.values)\n",
    "        scalersdict['allfeat'] = sc\n",
    "    else:\n",
    "        morph_feats = ['area', 'curv', 'thickness', 'volume']\n",
    "        XN = np.array([], dtype=np.double)\n",
    "        for ind, morph_feat in enumerate(morph_feats):\n",
    "            morph_cols = [col for col in df.columns if morph_feat in col]\n",
    "            X_morph = df.loc[:, morph_cols].values\n",
    "            Xn = (X_morph-np.min(X_morph, axis=1).reshape(-1,1))/(np.max(X_morph, axis=1).reshape(-1,1)-np.min(X_morph, axis=1).reshape(-1,1))\n",
    "            if ind == 0:\n",
    "                XN = np.append(XN, Xn).reshape(Xn.shape[0], -1)\n",
    "            else:\n",
    "                XN = np.concatenate([XN, Xn], axis=1)\n",
    "    return XN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal of this notebook:\n",
    "For each normalization method:<br>\n",
    "$\\;\\;\\;\\;\\;$ For each RFE classifier core:<br>\n",
    "$\\;\\;\\;\\;\\;$ $\\;\\;\\;\\;\\;$ For each data matrix (corr; uncorr; ucorrleft; ucorrright):<br>\n",
    "$\\;\\;\\;\\;\\;$ $\\;\\;\\;\\;\\;$ $\\;\\;\\;\\;\\;$ 1. Find the classifier with highest performance <br>\n",
    "$\\;\\;\\;\\;\\;$ $\\;\\;\\;\\;\\;$ $\\;\\;\\;\\;\\;$ 2. Use this classifier to train on all the training set<br>\n",
    "$\\;\\;\\;\\;\\;$ $\\;\\;\\;\\;\\;$ $\\;\\;\\;\\;\\;$ 3. Measure the performance on the testing set<br><br>\n",
    "\n",
    "Measure the performance in the testing set:\n",
    "1. Load the testing set\n",
    "2. Get the normalization object corresponding to the current normalization method\n",
    "3. Normalize the testing set using the normalization object of the training set\n",
    "4. Load the rfe+(RFE classifier core)\n",
    "5. Get the selected features used for learning the best ML model\n",
    "6. Select those features out of the normalized testing set\n",
    "7. Predict the labels of the output matrix from step 6\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = load('./Final_Results/ML/clf_lg2_train.joblib')\n",
    "clf_lab = load('./Final_Results/ML/ML/clf_lg2_train.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000000000000000000000000000000000000\n",
      "0.5912429378531072\n",
      "0.5410169491525424\n",
      "0.5996610169491525\n",
      "0.603050847457627\n",
      "0.5720621468926554\n",
      "0.6112146892655368\n",
      "0.5760169491525424\n",
      "0.5924858757062147\n"
     ]
    }
   ],
   "source": [
    "# print(clf['lSVM'].best_score_)\n",
    "# print(clf['pagg'].best_score_)\n",
    "# print(clf['lg'].best_score_)\n",
    "# print(clf['XGB'].best_score_)\n",
    "# print(clf['GNB'].best_score_)\n",
    "# print(clf['SVC'].best_score_)\n",
    "# print(clf['Rf'].best_score_)\n",
    "# print(clf['nn'].best_score_)\n",
    "\n",
    "print('00000000000000000000000000000000000000')\n",
    "print(clf_lab['lSVM'].best_score_)\n",
    "print(clf_lab['pagg'].best_score_)\n",
    "print(clf_lab['lg'].best_score_)\n",
    "print(clf_lab['XGB'].best_score_)\n",
    "print(clf_lab['GNB'].best_score_)\n",
    "print(clf_lab['SVC'].best_score_)\n",
    "print(clf_lab['Rf'].best_score_)\n",
    "print(clf_lab['nn'].best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = load('./Final_Results/ML/clf_lg2_train_corr.joblib')\n",
    "clf_lab = load('./Final_Results/ML/ML/clf_lg2_train_corr.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000000000000000000000000000000000000\n",
      "0.5843785310734464\n",
      "0.5522881355932203\n",
      "0.5878813559322034\n",
      "0.5790677966101695\n",
      "0.5330508474576272\n",
      "0.5875706214689266\n",
      "0.5709887005649718\n",
      "0.6096892655367231\n"
     ]
    }
   ],
   "source": [
    "# print(clf['lSVM'].best_score_)\n",
    "# print(clf['pagg'].best_score_)\n",
    "# print(clf['lg'].best_score_)\n",
    "# print(clf['XGB'].best_score_)\n",
    "# print(clf['GNB'].best_score_)\n",
    "# print(clf['SVC'].best_score_)\n",
    "# print(clf['Rf'].best_score_)\n",
    "# print(clf['nn'].best_score_)\n",
    "print('00000000000000000000000000000000000000')\n",
    "print(clf_lab['lSVM'].best_score_)\n",
    "print(clf_lab['pagg'].best_score_)\n",
    "print(clf_lab['lg'].best_score_)\n",
    "print(clf_lab['XGB'].best_score_)\n",
    "print(clf_lab['GNB'].best_score_)\n",
    "print(clf_lab['SVC'].best_score_)\n",
    "print(clf_lab['Rf'].best_score_)\n",
    "print(clf_lab['nn'].best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = load('./Final_Results/ML/clf_lg2_train_corr_l.joblib')\n",
    "clf_lab = load('./Final_Results/ML/ML/clf_lg2_train_corr_l.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000000000000000000000000000000000000\n",
      "0.5674858757062147\n",
      "0.5250564971751412\n",
      "0.5673728813559322\n",
      "0.5760734463276835\n",
      "0.5350282485875706\n",
      "0.5824858757062147\n",
      "0.5759887005649718\n",
      "0.5878813559322034\n"
     ]
    }
   ],
   "source": [
    "# print(clf['lSVM'].best_score_)\n",
    "# print(clf['pagg'].best_score_)\n",
    "# print(clf['lg'].best_score_)\n",
    "# print(clf['XGB'].best_score_)\n",
    "# print(clf['GNB'].best_score_)\n",
    "# print(clf['SVC'].best_score_)\n",
    "# print(clf['Rf'].best_score_)\n",
    "# print(clf['nn'].best_score_)\n",
    "print('00000000000000000000000000000000000000')\n",
    "print(clf_lab['lSVM'].best_score_)\n",
    "print(clf_lab['pagg'].best_score_)\n",
    "print(clf_lab['lg'].best_score_)\n",
    "print(clf_lab['XGB'].best_score_)\n",
    "print(clf_lab['GNB'].best_score_)\n",
    "print(clf_lab['SVC'].best_score_)\n",
    "print(clf_lab['Rf'].best_score_)\n",
    "print(clf_lab['nn'].best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = load('./Final_Results/ML/clf_lg1_train_corr_r.joblib')\n",
    "clf_lab = load('./Final_Results/ML/ML/clf_lg1_train_corr_r.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000000000000000000000000000000000000\n",
      "0.55954802259887\n",
      "0.5349717514124294\n",
      "0.5612146892655367\n",
      "0.5947175141242937\n",
      "0.5524858757062147\n",
      "0.5775706214689266\n",
      "0.5794350282485876\n",
      "0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "# print(clf['lSVM'].best_score_)\n",
    "# print(clf['pagg'].best_score_)\n",
    "# print(clf['lg'].best_score_)\n",
    "# print(clf['XGB'].best_score_)\n",
    "# print(clf['GNB'].best_score_)\n",
    "# print(clf['SVC'].best_score_)\n",
    "# print(clf['Rf'].best_score_)\n",
    "# print(clf['nn'].best_score_)\n",
    "print('00000000000000000000000000000000000000')\n",
    "print(clf_lab['lSVM'].best_score_)\n",
    "print(clf_lab['pagg'].best_score_)\n",
    "print(clf_lab['lg'].best_score_)\n",
    "print(clf_lab['XGB'].best_score_)\n",
    "print(clf_lab['GNB'].best_score_)\n",
    "print(clf_lab['SVC'].best_score_)\n",
    "print(clf_lab['Rf'].best_score_)\n",
    "print(clf_lab['nn'].best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the current results, I am going to proceed with \"lg1_train_corr\", classifier XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.603050847457627\n",
      "0.6096892655367231\n"
     ]
    }
   ],
   "source": [
    "selected_clc1 = load('./Final_Results/ML/ML/clf_lg2_train.joblib')['XGB']\n",
    "selected_clc2 = load('./Final_Results/ML/ML/clf_lg2_train_corr.joblib')['nn']\n",
    "\n",
    "print(selected_clc1.best_score_)\n",
    "selected_clc1 = selected_clc1.best_estimator_\n",
    "\n",
    "print(selected_clc2.best_score_)\n",
    "selected_clc2 = selected_clc2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "               colsample_bynode=1, colsample_bytree=0.8, gamma=1, gpu_id=-1,\n",
       "               importance_type='gain', interaction_constraints='',\n",
       "               learning_rate=0.5, max_delta_step=0, max_depth=6,\n",
       "               min_child_weight=0.01, missing=nan, monotone_constraints='()',\n",
       "               n_estimators=100, n_jobs=-1, num_parallel_tree=1, random_state=0,\n",
       "               reg_alpha=0.001, reg_lambda=0, scale_pos_weight=1, subsample=1,\n",
       "               tree_method='exact', validate_parameters=True, verbosity=None),\n",
       " MLPClassifier(activation='tanh', alpha=0.1, beta_1=0.5, beta_2=0.9,\n",
       "               hidden_layer_sizes=(100, 50, 25), learning_rate='adaptive',\n",
       "               max_iter=1000000))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_clc1, selected_clc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67, 545)\n",
      "0    36\n",
      "1    31\n",
      "Name: labels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load test dataset\n",
    "df_test = pd.read_csv('./Final_Results/INITIAL_SPLIT/test_fullbrain.csv', index_col=0)\n",
    "print(df_test.shape)\n",
    "print(df_test['labels'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline score:  0.5373134328358209\n"
     ]
    }
   ],
   "source": [
    "print('baseline score: ',36/(31+36))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "XN = mynormalize(df_test, allfeats=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the corresponding rfe object\n",
    "selected_rfe2 = load('./Final_Results/FS/rfetrain_corr_lg2.joblib')\n",
    "selected_rfe1 = load('./Final_Results/FS/rfetrain_lg2.joblib')\n",
    "\n",
    "\n",
    "Xtest1 = XN[:, np.where(selected_rfe1.support_)[0]]\n",
    "Xtest2 = XN[:, np.where(selected_rfe2.support_)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((597, 11), (597,))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training dataset to train the current model using all training set\n",
    "Xtrain1 = np.load('./Final_Results/FS/Xtrain_lg2.npy')\n",
    "ytrain1 = np.load('./Final_Results/FS/ytrain.npy')\n",
    "\n",
    "Xtrain.shape, ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10']\nexpected f18, f17, f11, f14, f12, f13, f16, f15, f20, f19, f21 in input data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-ed19f3143228>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'labels'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mselected_clc1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"**************************************************************************\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'labels'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mselected_clc2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, output_margin, ntree_limit, validate_features, base_margin)\u001b[0m\n\u001b[0;32m    886\u001b[0m             \u001b[0moutput_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mntree_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 888\u001b[1;33m             validate_features=validate_features)\n\u001b[0m\u001b[0;32m    889\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m             \u001b[1;31m# If output_margin is active, simply return the scores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features, training)\u001b[0m\n\u001b[0;32m   1569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1570\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalidate_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1571\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1572\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1573\u001b[0m         \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_bst_ulong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_validate_features\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   2129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2130\u001b[0m                 raise ValueError(msg.format(self.feature_names,\n\u001b[1;32m-> 2131\u001b[1;33m                                             data.feature_names))\n\u001b[0m\u001b[0;32m   2132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2133\u001b[0m     def get_split_value_histogram(self, feature, fmap='', bins=None,\n",
      "\u001b[1;31mValueError\u001b[0m: feature_names mismatch: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10']\nexpected f18, f17, f11, f14, f12, f13, f16, f15, f20, f19, f21 in input data"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_test['labels'].values, selected_clc1.predict(Xtest)))\n",
    "print(\"**************************************************************************\")\n",
    "print(classification_report(df_test['labels'].values, selected_clc2.predict(Xtest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       300\n",
      "           1       0.99      0.97      0.98       297\n",
      "\n",
      "    accuracy                           0.98       597\n",
      "   macro avg       0.98      0.98      0.98       597\n",
      "weighted avg       0.98      0.98      0.98       597\n",
      "\n"
     ]
    }
   ],
   "source": [
    "selected_clc = selected_clc.fit(Xtrain, ytrain)\n",
    "print(classification_report(ytrain, selected_clc.predict(Xtrain)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.11      0.19        36\n",
      "           1       0.47      0.90      0.62        31\n",
      "\n",
      "    accuracy                           0.48        67\n",
      "   macro avg       0.52      0.51      0.40        67\n",
      "weighted avg       0.52      0.48      0.38        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_test['labels'].values, selected_clc.predict(Xtest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "untitled",
   "language": "python",
   "name": "untitled"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
