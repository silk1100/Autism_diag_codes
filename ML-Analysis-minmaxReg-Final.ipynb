{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from joblib import load\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMinMax:\n",
    "    def __init__(self, axis):\n",
    "        self.sc = MinMaxScaler()\n",
    "        self.axis = axis\n",
    "\n",
    "    def fit(self, X):\n",
    "        if self.axis==1:\n",
    "            self.sc = self.sc.fit(X.transpose())\n",
    "        elif self.axis==0:\n",
    "            self.sc = self.sc.fit(X)\n",
    "        return self.sc\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.axis==1:\n",
    "            Xn = self.sc.transform(X.transpose()).transpose()\n",
    "        elif self.axis==0:\n",
    "            Xn = self.sc.transform(X)\n",
    "        return Xn\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        if self.axis==1:\n",
    "            self.sc = self.sc.fit(X.transpose())\n",
    "            Xn = self.sc.transform(X.transpose()).transpose()\n",
    "        elif self.axis==0:\n",
    "            self.sc = self.sc.fit(X)\n",
    "            Xn = self.sc.transform(X)\n",
    "        return Xn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67, 545)\n",
      "0    36\n",
      "1    31\n",
      "Name: labels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sc_train = load('./Final_Results/FS/sc_train_regminmax.joblib')\n",
    "sc_train_corr = load('./Final_Results/FS/sc_train_corr_regminmax.joblib')\n",
    "sc_train_corr_l = load('./Final_Results/FS/sc_train_corr_l_regminmax.joblib')\n",
    "sc_train_corr_r = load('./Final_Results/FS/sc_train_corr_r_regminmax.joblib')\n",
    "\n",
    "df_corr = pd.read_csv('./Final_Results/CORR_ANA/fullbrain_corr.csv', index_col=0)\n",
    "df_corr_l = pd.read_csv('./Final_Results/CORR_ANA/leftbrain_corr.csv', index_col=0)\n",
    "df_corr_r = pd.read_csv('./Final_Results/CORR_ANA/rightbrain_corr.csv', index_col=0)\n",
    "\n",
    "\n",
    "# Load test dataset\n",
    "df_test = pd.read_csv('./Final_Results/INITIAL_SPLIT/test_fullbrain.csv', index_col=0)\n",
    "df_test_corr = df_test.loc[:, df_corr.columns]\n",
    "df_test_corr_l = df_test.loc[:, df_corr_l.columns]\n",
    "df_test_corr_r = df_test.loc[:, df_corr_r.columns]\n",
    "\n",
    "print(df_test.shape)\n",
    "print(df_test['labels'].value_counts())\n",
    "\n",
    "XN = sc_train.transform(df_test.drop('labels', axis=1))\n",
    "XN_corr = sc_train_corr.transform(df_test_corr.drop('labels', axis=1))\n",
    "XN_corr_l = sc_train_corr_l.transform(df_test_corr_l.drop('labels', axis=1))\n",
    "XN_corr_r = sc_train_corr_r.transform(df_test_corr_r.drop('labels', axis=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal of this notebook:\n",
    "For each normalization method:<br>\n",
    "$\\;\\;\\;\\;\\;$ For each RFE classifier core:<br>\n",
    "$\\;\\;\\;\\;\\;$ $\\;\\;\\;\\;\\;$ For each data matrix (corr; uncorr; ucorrleft; ucorrright):<br>\n",
    "$\\;\\;\\;\\;\\;$ $\\;\\;\\;\\;\\;$ $\\;\\;\\;\\;\\;$ 1. Find the classifier with highest performance <br>\n",
    "$\\;\\;\\;\\;\\;$ $\\;\\;\\;\\;\\;$ $\\;\\;\\;\\;\\;$ 2. Use this classifier to train on all the training set<br>\n",
    "$\\;\\;\\;\\;\\;$ $\\;\\;\\;\\;\\;$ $\\;\\;\\;\\;\\;$ 3. Measure the performance on the testing set<br><br>\n",
    "\n",
    "Measure the performance in the testing set:\n",
    "1. Load the testing set\n",
    "2. Get the normalization object corresponding to the current normalization method\n",
    "3. Normalize the testing set using the normalization object of the training set\n",
    "4. Load the rfe+(RFE classifier core)\n",
    "5. Get the selected features used for learning the best ML model\n",
    "6. Select those features out of the normalized testing set\n",
    "7. Predict the labels of the output matrix from step 6\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression l1-norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = load('./Final_Results/ML/minmaxreg/clf_lg1_train.joblib')\n",
    "clf_corr = load('./Final_Results/ML/minmaxreg/clf_lg1_train_corr.joblib')\n",
    "clf_corr_l = load('./Final_Results/ML/minmaxreg/clf_lg1_train_corr_l.joblib')\n",
    "clf_corr_r = load('./Final_Results/ML/minmaxreg/clf_lg1_train_corr_r.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf_lg1_train\n",
      "0.5944350282485876\n",
      "0.6031638418079096\n",
      "0.5961016949152542\n",
      "0.6155367231638418\n",
      "0.5838135593220339\n",
      "0.6042937853107345\n",
      "0.5974576271186441\n",
      "0.6247457627118644\n",
      "0000000000000000000000000000000000000000000\n",
      "clf_lg1_train_corr\n",
      "0.6699717514124294\n",
      "0.6412994350282486\n",
      "0.6648587570621469\n",
      "0.663276836158192\n",
      "0.600677966101695\n",
      "0.6766101694915253\n",
      "0.6380508474576271\n",
      "0.6832485875706215\n",
      "0000000000000000000000000000000000000000000\n",
      "clf_lg1_train_corr_l\n",
      "0.621412429378531\n",
      "0.6178813559322034\n",
      "0.6213559322033897\n",
      "0.6329378531073446\n",
      "0.6075706214689266\n",
      "0.6394915254237288\n",
      "0.6297457627118644\n",
      "0.6396610169491526\n",
      "0000000000000000000000000000000000000000000\n",
      "clf_lg1_train_corr_r\n",
      "0.6315536723163842\n",
      "0.5911864406779661\n",
      "0.6314689265536724\n",
      "0.6165254237288136\n",
      "0.5941807909604521\n",
      "0.6366666666666666\n",
      "0.6363276836158193\n",
      "0.6518361581920904\n"
     ]
    }
   ],
   "source": [
    "print(\"clf_lg1_train\")\n",
    "print(clf['lSVM'].best_score_)\n",
    "print(clf['pagg'].best_score_)\n",
    "print(clf['lg'].best_score_)\n",
    "print(clf['XGB'].best_score_)\n",
    "print(clf['GNB'].best_score_)\n",
    "print(clf['SVC'].best_score_)\n",
    "print(clf['Rf'].best_score_)\n",
    "print(clf['nn'].best_score_)\n",
    "print(\"0000000000000000000000000000000000000000000\")\n",
    "print(\"clf_lg1_train_corr\")\n",
    "print(clf_corr['lSVM'].best_score_)\n",
    "print(clf_corr['pagg'].best_score_)\n",
    "print(clf_corr['lg'].best_score_)\n",
    "print(clf_corr['XGB'].best_score_)\n",
    "print(clf_corr['GNB'].best_score_)\n",
    "print(clf_corr['SVC'].best_score_)\n",
    "print(clf_corr['Rf'].best_score_)\n",
    "print(clf_corr['nn'].best_score_)\n",
    "print(\"0000000000000000000000000000000000000000000\")\n",
    "print(\"clf_lg1_train_corr_l\")\n",
    "print(clf_corr_l['lSVM'].best_score_)\n",
    "print(clf_corr_l['pagg'].best_score_)\n",
    "print(clf_corr_l['lg'].best_score_)\n",
    "print(clf_corr_l['XGB'].best_score_)\n",
    "print(clf_corr_l['GNB'].best_score_)\n",
    "print(clf_corr_l['SVC'].best_score_)\n",
    "print(clf_corr_l['Rf'].best_score_)\n",
    "print(clf_corr_l['nn'].best_score_)\n",
    "print(\"0000000000000000000000000000000000000000000\")\n",
    "print(\"clf_lg1_train_corr_r\")\n",
    "print(clf_corr_r['lSVM'].best_score_)\n",
    "print(clf_corr_r['pagg'].best_score_)\n",
    "print(clf_corr_r['lg'].best_score_)\n",
    "print(clf_corr_r['XGB'].best_score_)\n",
    "print(clf_corr_r['GNB'].best_score_)\n",
    "print(clf_corr_r['SVC'].best_score_)\n",
    "print(clf_corr_r['Rf'].best_score_)\n",
    "print(clf_corr_r['nn'].best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the current results, I am going to proceed with \"lg1_train_corr\", classifier XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected classifier 1: XGB_alldata with accuracy 0.6155367231638418\n",
      "selected classifier 2: nn_alldata with accuracy 0.6247457627118644\n",
      "selected classifier 3: lSVM_corr with accuracy 0.6699717514124294\n",
      "selected classifier 4: lSVM_alldata with accuracy 0.6648587570621469\n",
      "selected classifier 5: SVC_alldata with accuracy 0.663276836158192\n",
      "selected classifier 6: lSVM_corr with accuracy 0.6766101694915253\n",
      "selected classifier 7: lSVM_alldata with accuracy 0.6380508474576271\n",
      "selected classifier 8: SVC_alldata with accuracy 0.6832485875706215\n",
      "selected classifier 9: lSVM_alldata with accuracy 0.6394915254237288\n",
      "selected classifier 10: SVC_alldata with accuracy 0.6396610169491526\n",
      "selected classifier 11: lSVM_corr with accuracy 0.6315536723163842\n",
      "selected classifier 12: lSVM_alldata with accuracy 0.6314689265536724\n",
      "selected classifier 13: SVC_alldata with accuracy 0.6366666666666666\n",
      "selected classifier 14: lSVM_corr with accuracy 0.6363276836158193\n",
      "selected classifier 15: lSVM_alldata with accuracy 0.6518361581920904\n"
     ]
    }
   ],
   "source": [
    "selected_clc1 = clf['XGB'].best_estimator_\n",
    "selected_clc2 = clf['nn'].best_estimator_\n",
    "\n",
    "selected_clc3 = clf_corr['lSVM'].best_estimator_\n",
    "selected_clc4 = clf_corr['lg'].best_estimator_\n",
    "selected_clc5 = clf_corr['XGB'].best_estimator_\n",
    "selected_clc6 = clf_corr['SVC'].best_estimator_\n",
    "selected_clc7 = clf_corr['Rf'].best_estimator_\n",
    "selected_clc8 = clf_corr['nn'].best_estimator_\n",
    "\n",
    "selected_clc9 = clf_corr_l['SVC'].best_estimator_\n",
    "selected_clc10 = clf_corr_l['nn'].best_estimator_\n",
    "\n",
    "selected_clc11 = clf_corr_r['lSVM'].best_estimator_\n",
    "selected_clc12 = clf_corr_r['lg'].best_estimator_\n",
    "selected_clc13 = clf_corr_r['SVC'].best_estimator_\n",
    "selected_clc14 = clf_corr_r['Rf'].best_estimator_\n",
    "selected_clc15 = clf_corr_r['nn'].best_estimator_\n",
    "\n",
    "print(f'selected classifier 1: XGB_alldata with accuracy {clf[\"XGB\"].best_score_}')\n",
    "print(f'selected classifier 2: nn_alldata with accuracy {clf[\"nn\"].best_score_}')\n",
    "\n",
    "print(f'selected classifier 3: lSVM_corr with accuracy {clf_corr[\"lSVM\"].best_score_}')\n",
    "print(f'selected classifier 4: lSVM_alldata with accuracy {clf_corr[\"lg\"].best_score_}')\n",
    "print(f'selected classifier 5: SVC_alldata with accuracy {clf_corr[\"XGB\"].best_score_}')\n",
    "print(f'selected classifier 6: lSVM_corr with accuracy {clf_corr[\"SVC\"].best_score_}')\n",
    "print(f'selected classifier 7: lSVM_alldata with accuracy {clf_corr[\"Rf\"].best_score_}')\n",
    "print(f'selected classifier 8: SVC_alldata with accuracy {clf_corr[\"nn\"].best_score_}')\n",
    "\n",
    "print(f'selected classifier 9: lSVM_alldata with accuracy {clf_corr_l[\"SVC\"].best_score_}')\n",
    "print(f'selected classifier 10: SVC_alldata with accuracy {clf_corr_l[\"nn\"].best_score_}')\n",
    "\n",
    "print(f'selected classifier 11: lSVM_corr with accuracy {clf_corr_r[\"lSVM\"].best_score_}')\n",
    "print(f'selected classifier 12: lSVM_alldata with accuracy {clf_corr_r[\"lg\"].best_score_}')\n",
    "print(f'selected classifier 13: SVC_alldata with accuracy {clf_corr_r[\"SVC\"].best_score_}')\n",
    "print(f'selected classifier 14: lSVM_corr with accuracy {clf_corr_r[\"Rf\"].best_score_}')\n",
    "print(f'selected classifier 15: lSVM_alldata with accuracy {clf_corr_r[\"nn\"].best_score_}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the corresponding rfe object\n",
    "#clc1 & 2\n",
    "selected_rfe12 = load('./Final_Results/FS/Regular_minMaxNorm/rfetrain_lg1.joblib')\n",
    "Xtest12 = XN[:, np.where(selected_rfe12.support_)[0]]\n",
    "\n",
    "# clc3-8\n",
    "selected_rfe38 = load('./Final_Results/FS/Regular_minMaxNorm/rfetrain_corr_lg1.joblib')\n",
    "Xtest38 = XN_corr[:, np.where(selected_rfe38.support_)[0]]\n",
    "\n",
    "#clc9-10\n",
    "selected_rfe910 = load('./Final_Results/FS/Regular_minMaxNorm/rfetrain_corr_l_lg1.joblib')\n",
    "Xtest910 = XN_corr_l[:, np.where(selected_rfe910.support_)[0]]\n",
    "\n",
    "#clc11-15\n",
    "selected_rfe1115 = load('./Final_Results/FS/Regular_minMaxNorm/rfetrain_corr_r_lg1.joblib')\n",
    "Xtest1115 = XN_corr_r[:, np.where(selected_rfe1115.support_)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((597, 2), (597,))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training dataset to train the current model using all training set\n",
    "Xtrain = np.load('./Final_Results/FS/Regular_minMaxNorm/Xtrain_lg1.npy')\n",
    "Xtrain_corr = np.load('./Final_Results/FS/Regular_minMaxNorm/Xtrain_corr_lg1.npy')\n",
    "Xtrain_corr_l = np.load('./Final_Results/FS/Regular_minMaxNorm/Xtrain_corr_l_lg1.npy')\n",
    "Xtrain_corr_r = np.load('./Final_Results/FS/Regular_minMaxNorm/Xtrain_corr_r_lg1.npy')\n",
    "\n",
    "ytrain = np.load('./Final_Results/FS/Regular_minMaxNorm/ytrain_corr.npy')\n",
    "Xtrain.shape, ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.56      0.53        36\n",
      "           1       0.43      0.39      0.41        31\n",
      "\n",
      "    accuracy                           0.48        67\n",
      "   macro avg       0.47      0.47      0.47        67\n",
      "weighted avg       0.47      0.48      0.47        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc1\n",
    "print(classification_report(df_test['labels'].values, selected_clc1.predict(Xtest12)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61        36\n",
      "           1       0.55      0.55      0.55        31\n",
      "\n",
      "    accuracy                           0.58        67\n",
      "   macro avg       0.58      0.58      0.58        67\n",
      "weighted avg       0.58      0.58      0.58        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc2\n",
    "print(classification_report(df_test['labels'].values, selected_clc2.predict(Xtest12)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.53      0.54        36\n",
      "           1       0.47      0.48      0.48        31\n",
      "\n",
      "    accuracy                           0.51        67\n",
      "   macro avg       0.51      0.51      0.51        67\n",
      "weighted avg       0.51      0.51      0.51        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc3\n",
    "print(classification_report(df_test['labels'].values, selected_clc3.predict(Xtest38)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.53      0.55        36\n",
      "           1       0.50      0.55      0.52        31\n",
      "\n",
      "    accuracy                           0.54        67\n",
      "   macro avg       0.54      0.54      0.54        67\n",
      "weighted avg       0.54      0.54      0.54        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc4\n",
    "print(classification_report(df_test['labels'].values, selected_clc4.predict(Xtest38)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.53      0.53        36\n",
      "           1       0.45      0.45      0.45        31\n",
      "\n",
      "    accuracy                           0.49        67\n",
      "   macro avg       0.49      0.49      0.49        67\n",
      "weighted avg       0.49      0.49      0.49        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc5\n",
    "print(classification_report(df_test['labels'].values, selected_clc5.predict(Xtest38)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.53      0.54        36\n",
      "           1       0.48      0.52      0.50        31\n",
      "\n",
      "    accuracy                           0.52        67\n",
      "   macro avg       0.52      0.52      0.52        67\n",
      "weighted avg       0.52      0.52      0.52        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc6\n",
    "print(classification_report(df_test['labels'].values, selected_clc6.predict(Xtest38)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.61      0.60        36\n",
      "           1       0.53      0.52      0.52        31\n",
      "\n",
      "    accuracy                           0.57        67\n",
      "   macro avg       0.56      0.56      0.56        67\n",
      "weighted avg       0.57      0.57      0.57        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc7\n",
    "print(classification_report(df_test['labels'].values, selected_clc7.predict(Xtest38)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.53      0.54        36\n",
      "           1       0.48      0.52      0.50        31\n",
      "\n",
      "    accuracy                           0.52        67\n",
      "   macro avg       0.52      0.52      0.52        67\n",
      "weighted avg       0.52      0.52      0.52        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc8\n",
    "print(classification_report(df_test['labels'].values, selected_clc8.predict(Xtest38)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.69      0.67        36\n",
      "           1       0.61      0.55      0.58        31\n",
      "\n",
      "    accuracy                           0.63        67\n",
      "   macro avg       0.62      0.62      0.62        67\n",
      "weighted avg       0.63      0.63      0.62        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc9\n",
    "print(classification_report(df_test['labels'].values, selected_clc9.predict(Xtest910)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.72      0.66        36\n",
      "           1       0.58      0.45      0.51        31\n",
      "\n",
      "    accuracy                           0.60        67\n",
      "   macro avg       0.59      0.59      0.58        67\n",
      "weighted avg       0.59      0.60      0.59        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc10\n",
    "print(classification_report(df_test['labels'].values, selected_clc10.predict(Xtest910)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.61      0.62        36\n",
      "           1       0.56      0.58      0.57        31\n",
      "\n",
      "    accuracy                           0.60        67\n",
      "   macro avg       0.60      0.60      0.60        67\n",
      "weighted avg       0.60      0.60      0.60        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc11\n",
    "print(classification_report(df_test['labels'].values, selected_clc11.predict(Xtest1115)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.58      0.60        36\n",
      "           1       0.55      0.58      0.56        31\n",
      "\n",
      "    accuracy                           0.58        67\n",
      "   macro avg       0.58      0.58      0.58        67\n",
      "weighted avg       0.58      0.58      0.58        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc12\n",
    "print(classification_report(df_test['labels'].values, selected_clc12.predict(Xtest1115)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.47      0.52        36\n",
      "           1       0.50      0.61      0.55        31\n",
      "\n",
      "    accuracy                           0.54        67\n",
      "   macro avg       0.54      0.54      0.54        67\n",
      "weighted avg       0.55      0.54      0.54        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc13\n",
    "print(classification_report(df_test['labels'].values, selected_clc13.predict(Xtest1115)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.58      0.61        36\n",
      "           1       0.56      0.61      0.58        31\n",
      "\n",
      "    accuracy                           0.60        67\n",
      "   macro avg       0.60      0.60      0.60        67\n",
      "weighted avg       0.60      0.60      0.60        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc14\n",
    "print(classification_report(df_test['labels'].values, selected_clc14.predict(Xtest1115)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.53      0.57        36\n",
      "           1       0.53      0.61      0.57        31\n",
      "\n",
      "    accuracy                           0.57        67\n",
      "   macro avg       0.57      0.57      0.57        67\n",
      "weighted avg       0.57      0.57      0.57        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc15\n",
    "print(classification_report(df_test['labels'].values, selected_clc15.predict(Xtest1115)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression l2-norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = load('./Final_Results/ML/minmaxreg//clf_lg2_train.joblib')\n",
    "clf_corr = load('./Final_Results/ML/minmaxreg/clf_lg2_train_corr.joblib')\n",
    "clf_corr_l = load('./Final_Results/ML/minmaxreg/clf_lg2_train_corr_l.joblib')\n",
    "clf_corr_r = load('./Final_Results/ML/minmaxreg/clf_lg2_train_corr_r.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf_lg2_train\n",
      "0.6849435028248587\n",
      "0.662909604519774\n",
      "0.6883898305084746\n",
      "0.6834180790960451\n",
      "0.602457627118644\n",
      "0.6900847457627118\n",
      "0.6330508474576272\n",
      "0.6951694915254236\n",
      "0000000000000000000000000000000000000000000\n",
      "clf_lg2_train_corr\n",
      "0.6515536723163842\n",
      "0.6471186440677965\n",
      "0.6515819209039548\n",
      "0.6581638418079095\n",
      "0.604180790960452\n",
      "0.669915254237288\n",
      "0.6177401129943503\n",
      "0.6632768361581921\n",
      "0000000000000000000000000000000000000000000\n",
      "clf_lg2_train_corr_l\n",
      "0.6429661016949153\n",
      "0.6079661016949153\n",
      "0.6346610169491524\n",
      "0.6416101694915254\n",
      "0.6039830508474576\n",
      "0.6733050847457627\n",
      "0.6194915254237288\n",
      "0.6515819209039547\n",
      "0000000000000000000000000000000000000000000\n",
      "clf_lg2_train_corr_r\n",
      "0.6282485875706214\n",
      "0.5931920903954803\n",
      "0.6332485875706215\n",
      "0.6181920903954803\n",
      "0.5838418079096044\n",
      "0.64\n",
      "0.6346610169491524\n",
      "0.6448870056497176\n"
     ]
    }
   ],
   "source": [
    "print(\"clf_lg2_train\")\n",
    "print(clf['lSVM'].best_score_)\n",
    "print(clf['pagg'].best_score_)\n",
    "print(clf['lg'].best_score_)\n",
    "print(clf['XGB'].best_score_)\n",
    "print(clf['GNB'].best_score_)\n",
    "print(clf['SVC'].best_score_)\n",
    "print(clf['Rf'].best_score_)\n",
    "print(clf['nn'].best_score_)\n",
    "print(\"0000000000000000000000000000000000000000000\")\n",
    "print(\"clf_lg2_train_corr\")\n",
    "print(clf_corr['lSVM'].best_score_)\n",
    "print(clf_corr['pagg'].best_score_)\n",
    "print(clf_corr['lg'].best_score_)\n",
    "print(clf_corr['XGB'].best_score_)\n",
    "print(clf_corr['GNB'].best_score_)\n",
    "print(clf_corr['SVC'].best_score_)\n",
    "print(clf_corr['Rf'].best_score_)\n",
    "print(clf_corr['nn'].best_score_)\n",
    "print(\"0000000000000000000000000000000000000000000\")\n",
    "print(\"clf_lg2_train_corr_l\")\n",
    "print(clf_corr_l['lSVM'].best_score_)\n",
    "print(clf_corr_l['pagg'].best_score_)\n",
    "print(clf_corr_l['lg'].best_score_)\n",
    "print(clf_corr_l['XGB'].best_score_)\n",
    "print(clf_corr_l['GNB'].best_score_)\n",
    "print(clf_corr_l['SVC'].best_score_)\n",
    "print(clf_corr_l['Rf'].best_score_)\n",
    "print(clf_corr_l['nn'].best_score_)\n",
    "print(\"0000000000000000000000000000000000000000000\")\n",
    "print(\"clf_lg2_train_corr_r\")\n",
    "print(clf_corr_r['lSVM'].best_score_)\n",
    "print(clf_corr_r['pagg'].best_score_)\n",
    "print(clf_corr_r['lg'].best_score_)\n",
    "print(clf_corr_r['XGB'].best_score_)\n",
    "print(clf_corr_r['GNB'].best_score_)\n",
    "print(clf_corr_r['SVC'].best_score_)\n",
    "print(clf_corr_r['Rf'].best_score_)\n",
    "print(clf_corr_r['nn'].best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected classifier 1: lSVM_alldata with accuracy 0.6849435028248587\n",
      "selected classifier 2: lg_alldata with accuracy 0.6883898305084746\n",
      "selected classifier 3: SVC_alldata with accuracy 0.6900847457627118\n",
      "selected classifier 4: nn_alldata with accuracy 0.6951694915254236\n",
      "selected classifier 5: lSVM_corr with accuracy 0.6515536723163842\n",
      "selected classifier 6: lg_corr with accuracy 0.6515819209039548\n",
      "selected classifier 7: XGB_corr with accuracy 0.6581638418079095\n",
      "selected classifier 8: SVC_corr with accuracy 0.669915254237288\n",
      "selected classifier 9: nn_corr with accuracy 0.6632768361581921\n",
      "selected classifier 10: lSVM_corr_l with accuracy 0.6429661016949153\n",
      "selected classifier 11: XGB_corr_l with accuracy 0.6416101694915254\n",
      "selected classifier 12: SVC_corr_l with accuracy 0.6733050847457627\n",
      "selected classifier 13: nn_corr_l with accuracy 0.6515819209039547\n",
      "selected classifier 14: lSVM_corr_r with accuracy 0.6282485875706214\n",
      "selected classifier 15: lg_corr_r with accuracy 0.6332485875706215\n",
      "selected classifier 16: SVC_corr_r with accuracy 0.64\n",
      "selected classifier 17: Rf_corr_r with accuracy 0.6346610169491524\n",
      "selected classifier 18: nn_corr_r with accuracy 0.6448870056497176\n"
     ]
    }
   ],
   "source": [
    "selected_clc1 = clf['lSVM'].best_estimator_\n",
    "selected_clc2 = clf['lg'].best_estimator_\n",
    "selected_clc3 = clf['SVC'].best_estimator_\n",
    "selected_clc4 = clf['nn'].best_estimator_\n",
    "\n",
    "selected_clc5 = clf_corr['lSVM'].best_estimator_\n",
    "selected_clc6 = clf_corr['lg'].best_estimator_\n",
    "selected_clc7 = clf_corr['XGB'].best_estimator_\n",
    "selected_clc8 = clf_corr['SVC'].best_estimator_\n",
    "selected_clc9 = clf_corr['nn'].best_estimator_\n",
    "\n",
    "selected_clc10 = clf_corr_l['lSVM'].best_estimator_\n",
    "selected_clc11 = clf_corr_l['XGB'].best_estimator_\n",
    "selected_clc12 = clf_corr_l['SVC'].best_estimator_\n",
    "selected_clc13 = clf_corr_l['nn'].best_estimator_\n",
    "\n",
    "selected_clc14 = clf_corr_r['lSVM'].best_estimator_\n",
    "selected_clc15 = clf_corr_r['lg'].best_estimator_\n",
    "selected_clc16 = clf_corr_r['SVC'].best_estimator_\n",
    "selected_clc17 = clf_corr_r['Rf'].best_estimator_\n",
    "selected_clc18 = clf_corr_r['nn'].best_estimator_\n",
    "\n",
    "print(f'selected classifier 1: lSVM_alldata with accuracy {clf[\"lSVM\"].best_score_}')\n",
    "print(f'selected classifier 2: lg_alldata with accuracy {clf[\"lg\"].best_score_}')\n",
    "print(f'selected classifier 3: SVC_alldata with accuracy {clf[\"SVC\"].best_score_}')\n",
    "print(f'selected classifier 4: nn_alldata with accuracy {clf[\"nn\"].best_score_}')\n",
    "\n",
    "print(f'selected classifier 5: lSVM_corr with accuracy {clf_corr[\"lSVM\"].best_score_}')\n",
    "print(f'selected classifier 6: lg_corr with accuracy {clf_corr[\"lg\"].best_score_}')\n",
    "print(f'selected classifier 7: XGB_corr with accuracy {clf_corr[\"XGB\"].best_score_}')\n",
    "print(f'selected classifier 8: SVC_corr with accuracy {clf_corr[\"SVC\"].best_score_}')\n",
    "print(f'selected classifier 9: nn_corr with accuracy {clf_corr[\"nn\"].best_score_}')\n",
    "\n",
    "print(f'selected classifier 10: lSVM_corr_l with accuracy {clf_corr_l[\"lSVM\"].best_score_}')\n",
    "print(f'selected classifier 11: XGB_corr_l with accuracy {clf_corr_l[\"XGB\"].best_score_}')\n",
    "print(f'selected classifier 12: SVC_corr_l with accuracy {clf_corr_l[\"SVC\"].best_score_}')\n",
    "print(f'selected classifier 13: nn_corr_l with accuracy {clf_corr_l[\"nn\"].best_score_}')\n",
    "\n",
    "print(f'selected classifier 14: lSVM_corr_r with accuracy {clf_corr_r[\"lSVM\"].best_score_}')\n",
    "print(f'selected classifier 15: lg_corr_r with accuracy {clf_corr_r[\"lg\"].best_score_}')\n",
    "print(f'selected classifier 16: SVC_corr_r with accuracy {clf_corr_r[\"SVC\"].best_score_}')\n",
    "print(f'selected classifier 17: Rf_corr_r with accuracy {clf_corr_r[\"Rf\"].best_score_}')\n",
    "print(f'selected classifier 18: nn_corr_r with accuracy {clf_corr_r[\"nn\"].best_score_}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the corresponding rfe object\n",
    "#clc14\n",
    "selected_rfe14 = load('./Final_Results/FS/Regular_minMaxNorm/rfetrain_lg2.joblib')\n",
    "Xtest14 = XN[:, np.where(selected_rfe14.support_)[0]]\n",
    "\n",
    "# clc59\n",
    "selected_rfe59 = load('./Final_Results/FS/Regular_minMaxNorm/rfetrain_corr_lg2.joblib')\n",
    "Xtest59 = XN_corr[:, np.where(selected_rfe59.support_)[0]]\n",
    "\n",
    "# clc1013\n",
    "selected_rfe1013 = load('./Final_Results/FS/Regular_minMaxNorm/rfetrain_corr_l_lg2.joblib')\n",
    "Xtest1013 = XN_corr_l[:, np.where(selected_rfe1013.support_)[0]]\n",
    "\n",
    "# clc1418\n",
    "selected_rfe1418 = load('./Final_Results/FS/Regular_minMaxNorm/rfetrain_corr_r_lg2.joblib')\n",
    "Xtest1418 = XN_corr_r[:, np.where(selected_rfe1418.support_)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training dataset to train the current model using all training set\n",
    "# clc1&2\n",
    "Xtrain14 = np.load('./Final_Results/FS/Regular_minMaxNorm/Xtrain_lg2.npy')\n",
    "\n",
    "# clc3\n",
    "Xtrain59 = np.load('./Final_Results/FS/Regular_minMaxNorm/Xtrain_corr_lg2.npy')\n",
    "\n",
    "\n",
    "# clc4\n",
    "Xtrain1013 = np.load('./Final_Results/FS/Regular_minMaxNorm/Xtrain_corr_l_lg2.npy')\n",
    "\n",
    "# clc5\n",
    "Xtrain1418 = np.load('./Final_Results/FS/Regular_minMaxNorm/Xtrain_corr_r_lg2.npy')\n",
    "\n",
    "\n",
    "ytrain = np.load('./Final_Results/FS/Regular_minMaxNorm/ytrain_corr.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.61      0.62        36\n",
      "           1       0.56      0.58      0.57        31\n",
      "\n",
      "    accuracy                           0.60        67\n",
      "   macro avg       0.60      0.60      0.60        67\n",
      "weighted avg       0.60      0.60      0.60        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc1\n",
    "print(classification_report(df_test['labels'].values, selected_clc1.predict(Xtest14)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.61      0.60        36\n",
      "           1       0.53      0.52      0.52        31\n",
      "\n",
      "    accuracy                           0.57        67\n",
      "   macro avg       0.56      0.56      0.56        67\n",
      "weighted avg       0.57      0.57      0.57        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc2\n",
    "print(classification_report(df_test['labels'].values, selected_clc2.predict(Xtest14)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63        36\n",
      "           1       0.57      0.55      0.56        31\n",
      "\n",
      "    accuracy                           0.60        67\n",
      "   macro avg       0.59      0.59      0.59        67\n",
      "weighted avg       0.60      0.60      0.60        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc3\n",
    "print(classification_report(df_test['labels'].values, selected_clc3.predict(Xtest14)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61        36\n",
      "           1       0.55      0.55      0.55        31\n",
      "\n",
      "    accuracy                           0.58        67\n",
      "   macro avg       0.58      0.58      0.58        67\n",
      "weighted avg       0.58      0.58      0.58        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc4\n",
    "print(classification_report(df_test['labels'].values, selected_clc4.predict(Xtest14)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.58      0.59        36\n",
      "           1       0.53      0.55      0.54        31\n",
      "\n",
      "    accuracy                           0.57        67\n",
      "   macro avg       0.57      0.57      0.57        67\n",
      "weighted avg       0.57      0.57      0.57        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc5\n",
    "print(classification_report(df_test['labels'].values, selected_clc5.predict(Xtest59)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.58      0.60        36\n",
      "           1       0.55      0.58      0.56        31\n",
      "\n",
      "    accuracy                           0.58        67\n",
      "   macro avg       0.58      0.58      0.58        67\n",
      "weighted avg       0.58      0.58      0.58        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc6\n",
    "print(classification_report(df_test['labels'].values, selected_clc6.predict(Xtest59)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63        36\n",
      "           1       0.57      0.55      0.56        31\n",
      "\n",
      "    accuracy                           0.60        67\n",
      "   macro avg       0.59      0.59      0.59        67\n",
      "weighted avg       0.60      0.60      0.60        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc7\n",
    "print(classification_report(df_test['labels'].values, selected_clc7.predict(Xtest59)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.53      0.57        36\n",
      "           1       0.53      0.61      0.57        31\n",
      "\n",
      "    accuracy                           0.57        67\n",
      "   macro avg       0.57      0.57      0.57        67\n",
      "weighted avg       0.57      0.57      0.57        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc8\n",
    "print(classification_report(df_test['labels'].values, selected_clc8.predict(Xtest59)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64        36\n",
      "           1       0.58      0.58      0.58        31\n",
      "\n",
      "    accuracy                           0.61        67\n",
      "   macro avg       0.61      0.61      0.61        67\n",
      "weighted avg       0.61      0.61      0.61        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc9\n",
    "print(classification_report(df_test['labels'].values, selected_clc9.predict(Xtest59)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.67      0.62        36\n",
      "           1       0.52      0.42      0.46        31\n",
      "\n",
      "    accuracy                           0.55        67\n",
      "   macro avg       0.55      0.54      0.54        67\n",
      "weighted avg       0.55      0.55      0.55        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc10\n",
    "print(classification_report(df_test['labels'].values, selected_clc10.predict(Xtest1013)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.50      0.53        36\n",
      "           1       0.49      0.55      0.52        31\n",
      "\n",
      "    accuracy                           0.52        67\n",
      "   macro avg       0.52      0.52      0.52        67\n",
      "weighted avg       0.53      0.52      0.52        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc11\n",
    "print(classification_report(df_test['labels'].values, selected_clc11.predict(Xtest1013)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.56      0.59        36\n",
      "           1       0.54      0.61      0.58        31\n",
      "\n",
      "    accuracy                           0.58        67\n",
      "   macro avg       0.58      0.58      0.58        67\n",
      "weighted avg       0.59      0.58      0.58        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc12\n",
    "print(classification_report(df_test['labels'].values, selected_clc12.predict(Xtest1013)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.72      0.66        36\n",
      "           1       0.58      0.45      0.51        31\n",
      "\n",
      "    accuracy                           0.60        67\n",
      "   macro avg       0.59      0.59      0.58        67\n",
      "weighted avg       0.59      0.60      0.59        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc13\n",
    "print(classification_report(df_test['labels'].values, selected_clc13.predict(Xtest1013)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64        36\n",
      "           1       0.58      0.58      0.58        31\n",
      "\n",
      "    accuracy                           0.61        67\n",
      "   macro avg       0.61      0.61      0.61        67\n",
      "weighted avg       0.61      0.61      0.61        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc14\n",
    "print(classification_report(df_test['labels'].values, selected_clc14.predict(Xtest1418)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.61      0.62        36\n",
      "           1       0.56      0.58      0.57        31\n",
      "\n",
      "    accuracy                           0.60        67\n",
      "   macro avg       0.60      0.60      0.60        67\n",
      "weighted avg       0.60      0.60      0.60        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc15\n",
    "print(classification_report(df_test['labels'].values, selected_clc15.predict(Xtest1418)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.50      0.55        36\n",
      "           1       0.51      0.61      0.56        31\n",
      "\n",
      "    accuracy                           0.55        67\n",
      "   macro avg       0.56      0.56      0.55        67\n",
      "weighted avg       0.56      0.55      0.55        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc16\n",
    "print(classification_report(df_test['labels'].values, selected_clc16.predict(Xtest1418)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.61      0.62        36\n",
      "           1       0.56      0.58      0.57        31\n",
      "\n",
      "    accuracy                           0.60        67\n",
      "   macro avg       0.60      0.60      0.60        67\n",
      "weighted avg       0.60      0.60      0.60        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc17\n",
    "print(classification_report(df_test['labels'].values, selected_clc17.predict(Xtest1418)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.56      0.58        36\n",
      "           1       0.53      0.58      0.55        31\n",
      "\n",
      "    accuracy                           0.57        67\n",
      "   macro avg       0.57      0.57      0.57        67\n",
      "weighted avg       0.57      0.57      0.57        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc18\n",
    "print(classification_report(df_test['labels'].values, selected_clc18.predict(Xtest1418)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:45:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample_bytree, gamma, min_child_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "selected_clc1 = selected_clc1.fit(Xtrain14, ytrain)\n",
    "selected_clc2 = selected_clc2.fit(Xtrain14, ytrain)\n",
    "selected_clc3 = selected_clc3.fit(Xtrain14, ytrain)\n",
    "selected_clc4 = selected_clc4.fit(Xtrain14, ytrain)\n",
    "selected_clc5 = selected_clc5.fit(Xtrain59, ytrain)\n",
    "selected_clc6 = selected_clc6.fit(Xtrain59, ytrain)\n",
    "selected_clc7 = selected_clc7.fit(Xtrain59, ytrain)\n",
    "selected_clc8 = selected_clc8.fit(Xtrain59, ytrain)\n",
    "selected_clc9 = selected_clc9.fit(Xtrain59, ytrain)\n",
    "selected_clc10 = selected_clc10.fit(Xtrain1013, ytrain)\n",
    "selected_clc11 = selected_clc11.fit(Xtrain1013, ytrain)\n",
    "selected_clc12 = selected_clc12.fit(Xtrain1013, ytrain)\n",
    "selected_clc13 = selected_clc13.fit(Xtrain1013, ytrain)\n",
    "selected_clc14 = selected_clc14.fit(Xtrain1418, ytrain)\n",
    "selected_clc15 = selected_clc15.fit(Xtrain1418, ytrain)\n",
    "selected_clc16 = selected_clc16.fit(Xtrain1418, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.61      0.62        36\n",
      "           1       0.56      0.58      0.57        31\n",
      "\n",
      "    accuracy                           0.60        67\n",
      "   macro avg       0.60      0.60      0.60        67\n",
      "weighted avg       0.60      0.60      0.60        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc1\n",
    "print(classification_report(df_test['labels'].values, selected_clc1.predict(Xtest14)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.61      0.60        36\n",
      "           1       0.53      0.52      0.52        31\n",
      "\n",
      "    accuracy                           0.57        67\n",
      "   macro avg       0.56      0.56      0.56        67\n",
      "weighted avg       0.57      0.57      0.57        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc2\n",
    "print(classification_report(df_test['labels'].values, selected_clc2.predict(Xtest14)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.61      0.60        36\n",
      "           1       0.53      0.52      0.52        31\n",
      "\n",
      "    accuracy                           0.57        67\n",
      "   macro avg       0.56      0.56      0.56        67\n",
      "weighted avg       0.57      0.57      0.57        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc3\n",
    "print(classification_report(df_test['labels'].values, selected_clc2.predict(Xtest14)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64        36\n",
      "           1       0.58      0.58      0.58        31\n",
      "\n",
      "    accuracy                           0.61        67\n",
      "   macro avg       0.61      0.61      0.61        67\n",
      "weighted avg       0.61      0.61      0.61        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc4\n",
    "print(classification_report(df_test['labels'].values, selected_clc4.predict(Xtest14)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.58      0.59        36\n",
      "           1       0.53      0.55      0.54        31\n",
      "\n",
      "    accuracy                           0.57        67\n",
      "   macro avg       0.57      0.57      0.57        67\n",
      "weighted avg       0.57      0.57      0.57        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc5\n",
    "print(classification_report(df_test['labels'].values, selected_clc5.predict(Xtest59)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.58      0.60        36\n",
      "           1       0.55      0.58      0.56        31\n",
      "\n",
      "    accuracy                           0.58        67\n",
      "   macro avg       0.58      0.58      0.58        67\n",
      "weighted avg       0.58      0.58      0.58        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc6\n",
    "print(classification_report(df_test['labels'].values, selected_clc6.predict(Xtest59)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63        36\n",
      "           1       0.57      0.55      0.56        31\n",
      "\n",
      "    accuracy                           0.60        67\n",
      "   macro avg       0.59      0.59      0.59        67\n",
      "weighted avg       0.60      0.60      0.60        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc7\n",
    "print(classification_report(df_test['labels'].values, selected_clc7.predict(Xtest59)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.53      0.57        36\n",
      "           1       0.53      0.61      0.57        31\n",
      "\n",
      "    accuracy                           0.57        67\n",
      "   macro avg       0.57      0.57      0.57        67\n",
      "weighted avg       0.57      0.57      0.57        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc8\n",
    "print(classification_report(df_test['labels'].values, selected_clc8.predict(Xtest59)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.64      0.62        36\n",
      "           1       0.55      0.52      0.53        31\n",
      "\n",
      "    accuracy                           0.58        67\n",
      "   macro avg       0.58      0.58      0.58        67\n",
      "weighted avg       0.58      0.58      0.58        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc9\n",
    "print(classification_report(df_test['labels'].values, selected_clc9.predict(Xtest59)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.67      0.62        36\n",
      "           1       0.52      0.42      0.46        31\n",
      "\n",
      "    accuracy                           0.55        67\n",
      "   macro avg       0.55      0.54      0.54        67\n",
      "weighted avg       0.55      0.55      0.55        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc10\n",
    "print(classification_report(df_test['labels'].values, selected_clc10.predict(Xtest1013)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.50      0.53        36\n",
      "           1       0.49      0.55      0.52        31\n",
      "\n",
      "    accuracy                           0.52        67\n",
      "   macro avg       0.52      0.52      0.52        67\n",
      "weighted avg       0.53      0.52      0.52        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc11\n",
    "print(classification_report(df_test['labels'].values, selected_clc11.predict(Xtest1013)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.56      0.59        36\n",
      "           1       0.54      0.61      0.58        31\n",
      "\n",
      "    accuracy                           0.58        67\n",
      "   macro avg       0.58      0.58      0.58        67\n",
      "weighted avg       0.59      0.58      0.58        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc12\n",
    "print(classification_report(df_test['labels'].values, selected_clc12.predict(Xtest1013)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.75      0.67        36\n",
      "           1       0.59      0.42      0.49        31\n",
      "\n",
      "    accuracy                           0.60        67\n",
      "   macro avg       0.60      0.58      0.58        67\n",
      "weighted avg       0.60      0.60      0.59        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc13\n",
    "print(classification_report(df_test['labels'].values, selected_clc13.predict(Xtest1013)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64        36\n",
      "           1       0.58      0.58      0.58        31\n",
      "\n",
      "    accuracy                           0.61        67\n",
      "   macro avg       0.61      0.61      0.61        67\n",
      "weighted avg       0.61      0.61      0.61        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc14\n",
    "print(classification_report(df_test['labels'].values, selected_clc14.predict(Xtest1418)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.61      0.62        36\n",
      "           1       0.56      0.58      0.57        31\n",
      "\n",
      "    accuracy                           0.60        67\n",
      "   macro avg       0.60      0.60      0.60        67\n",
      "weighted avg       0.60      0.60      0.60        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc14\n",
    "print(classification_report(df_test['labels'].values, selected_clc15.predict(Xtest1418)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.50      0.55        36\n",
      "           1       0.51      0.61      0.56        31\n",
      "\n",
      "    accuracy                           0.55        67\n",
      "   macro avg       0.56      0.56      0.55        67\n",
      "weighted avg       0.56      0.55      0.55        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc14\n",
    "print(classification_report(df_test['labels'].values, selected_clc16.predict(Xtest1418)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.61      0.62        36\n",
      "           1       0.56      0.58      0.57        31\n",
      "\n",
      "    accuracy                           0.60        67\n",
      "   macro avg       0.60      0.60      0.60        67\n",
      "weighted avg       0.60      0.60      0.60        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc14\n",
    "print(classification_report(df_test['labels'].values, selected_clc17.predict(Xtest1418)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.56      0.58        36\n",
      "           1       0.53      0.58      0.55        31\n",
      "\n",
      "    accuracy                           0.57        67\n",
      "   macro avg       0.57      0.57      0.57        67\n",
      "weighted avg       0.57      0.57      0.57        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc14\n",
    "print(classification_report(df_test['labels'].values, selected_clc18.predict(Xtest1418)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = load('./Final_Results/ML/minmaxreg/clf_svm_train.joblib')\n",
    "clf_corr = load('./Final_Results/ML/minmaxreg/clf_svm_train_corr.joblib')\n",
    "clf_corr_l = load('./Final_Results/ML/minmaxreg/clf_svm_train_corr_l.joblib')\n",
    "clf_corr_r = load('./Final_Results/ML/minmaxreg/clf_svm_train_corr_r.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf_svm_train\n",
      "0.663361581920904\n",
      "0.6277683615819208\n",
      "0.6617231638418078\n",
      "0.6582768361581921\n",
      "0.5669209039548022\n",
      "0.6899435028248586\n",
      "0.6163841807909605\n",
      "0.6784463276836158\n",
      "0000000000000000000000000000000000000000000\n",
      "clf_svm_train_corr\n",
      "0.6581073446327683\n",
      "0.6414406779661017\n",
      "0.6530790960451978\n",
      "0.6581638418079095\n",
      "0.5836440677966102\n",
      "0.6701129943502824\n",
      "0.6145480225988701\n",
      "0.6702824858757063\n",
      "0000000000000000000000000000000000000000000\n",
      "clf_svm_train_corr_l\n",
      "0.6464406779661017\n",
      "0.6033050847457627\n",
      "0.6430790960451978\n",
      "0.6498870056497175\n",
      "0.5805084745762711\n",
      "0.6732485875706216\n",
      "0.6262429378531074\n",
      "0.6586158192090397\n",
      "0000000000000000000000000000000000000000000\n",
      "clf_svm_train_corr_r\n",
      "0.612994350282486\n",
      "0.5861864406779661\n",
      "0.611412429378531\n",
      "0.617909604519774\n",
      "0.5686440677966103\n",
      "0.6245197740112994\n",
      "0.6144915254237289\n",
      "0.6316949152542373\n"
     ]
    }
   ],
   "source": [
    "print(\"clf_svm_train\")\n",
    "print(clf['lSVM'].best_score_)\n",
    "print(clf['pagg'].best_score_)\n",
    "print(clf['lg'].best_score_)\n",
    "print(clf['XGB'].best_score_)\n",
    "print(clf['GNB'].best_score_)\n",
    "print(clf['SVC'].best_score_)\n",
    "print(clf['Rf'].best_score_)\n",
    "print(clf['nn'].best_score_)\n",
    "print(\"0000000000000000000000000000000000000000000\")\n",
    "print(\"clf_svm_train_corr\")\n",
    "print(clf_corr['lSVM'].best_score_)\n",
    "print(clf_corr['pagg'].best_score_)\n",
    "print(clf_corr['lg'].best_score_)\n",
    "print(clf_corr['XGB'].best_score_)\n",
    "print(clf_corr['GNB'].best_score_)\n",
    "print(clf_corr['SVC'].best_score_)\n",
    "print(clf_corr['Rf'].best_score_)\n",
    "print(clf_corr['nn'].best_score_)\n",
    "print(\"0000000000000000000000000000000000000000000\")\n",
    "print(\"clf_svm_train_corr_l\")\n",
    "print(clf_corr_l['lSVM'].best_score_)\n",
    "print(clf_corr_l['pagg'].best_score_)\n",
    "print(clf_corr_l['lg'].best_score_)\n",
    "print(clf_corr_l['XGB'].best_score_)\n",
    "print(clf_corr_l['GNB'].best_score_)\n",
    "print(clf_corr_l['SVC'].best_score_)\n",
    "print(clf_corr_l['Rf'].best_score_)\n",
    "print(clf_corr_l['nn'].best_score_)\n",
    "print(\"0000000000000000000000000000000000000000000\")\n",
    "print(\"clf_svm_train_corr_r\")\n",
    "print(clf_corr_r['lSVM'].best_score_)\n",
    "print(clf_corr_r['pagg'].best_score_)\n",
    "print(clf_corr_r['lg'].best_score_)\n",
    "print(clf_corr_r['XGB'].best_score_)\n",
    "print(clf_corr_r['GNB'].best_score_)\n",
    "print(clf_corr_r['SVC'].best_score_)\n",
    "print(clf_corr_r['Rf'].best_score_)\n",
    "print(clf_corr_r['nn'].best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected classifier 1: lSVM_alldata with accuracy 0.663361581920904\n",
      "selected classifier 2: lg_alldata with accuracy 0.6617231638418078\n",
      "selected classifier 3: XGB_alldata with accuracy 0.6582768361581921\n",
      "selected classifier 4: SVC_corr with accuracy 0.6899435028248586\n",
      "selected classifier 5: nn_corr with accuracy 0.6784463276836158\n",
      "selected classifier 6: lSVM_corr with accuracy 0.6581073446327683\n",
      "selected classifier 7: lg_corr with accuracy 0.6530790960451978\n",
      "selected classifier 8: XGB_corr with accuracy 0.6581638418079095\n",
      "selected classifier 9: SVC_corr with accuracy 0.6701129943502824\n",
      "selected classifier 10: nn_corr with accuracy 0.6702824858757063\n",
      "selected classifier 11: lSVM_corr_l with accuracy 0.6464406779661017\n",
      "selected classifier 12: lg_corr_l with accuracy 0.6430790960451978\n",
      "selected classifier 13: XGB_corr_l with accuracy 0.6498870056497175\n",
      "selected classifier 14: SVC_corr_l with accuracy 0.6732485875706216\n",
      "selected classifier 15: nn_corr_l with accuracy 0.6586158192090397\n",
      "selected classifier 16: lSVM_corr_r with accuracy 0.612994350282486\n",
      "selected classifier 17: lg_corr_r with accuracy 0.611412429378531\n",
      "selected classifier 18: XGB_corr_r with accuracy 0.617909604519774\n",
      "selected classifier 19: SVC_corr_r with accuracy 0.6245197740112994\n",
      "selected classifier 20: nn_corr_r with accuracy 0.6316949152542373\n"
     ]
    }
   ],
   "source": [
    "selected_clc1 = clf['lSVM'].best_estimator_\n",
    "selected_clc2 = clf['lg'].best_estimator_\n",
    "selected_clc3 = clf['XGB'].best_estimator_\n",
    "selected_clc4 = clf['SVC'].best_estimator_\n",
    "selected_clc5 = clf['nn'].best_estimator_\n",
    "\n",
    "selected_clc6 = clf_corr['lSVM'].best_estimator_\n",
    "selected_clc7 = clf_corr['lg'].best_estimator_\n",
    "selected_clc8 = clf_corr['XGB'].best_estimator_\n",
    "selected_clc9 = clf_corr['SVC'].best_estimator_\n",
    "selected_clc10 = clf_corr['nn'].best_estimator_\n",
    "\n",
    "selected_clc11 = clf_corr_l['lSVM'].best_estimator_\n",
    "selected_clc12 = clf_corr_l['lg'].best_estimator_\n",
    "selected_clc13 = clf_corr_l['XGB'].best_estimator_\n",
    "selected_clc14 = clf_corr_l['SVC'].best_estimator_\n",
    "selected_clc15 = clf_corr_l['nn'].best_estimator_\n",
    "\n",
    "selected_clc16 = clf_corr_r['lSVM'].best_estimator_\n",
    "selected_clc17 = clf_corr_r['lg'].best_estimator_\n",
    "selected_clc18 = clf_corr_r['XGB'].best_estimator_\n",
    "selected_clc19 = clf_corr_r['SVC'].best_estimator_\n",
    "selected_clc20 = clf_corr_r['nn'].best_estimator_\n",
    "\n",
    "print(f\"selected classifier 1: lSVM_alldata with accuracy {clf['lSVM'].best_score_}\")\n",
    "print(f\"selected classifier 2: lg_alldata with accuracy {clf['lg'].best_score_}\")\n",
    "print(f\"selected classifier 3: XGB_alldata with accuracy {clf['XGB'].best_score_}\")\n",
    "print(f\"selected classifier 4: SVC_corr with accuracy {clf['SVC'].best_score_}\")\n",
    "print(f\"selected classifier 5: nn_corr with accuracy {clf['nn'].best_score_}\")\n",
    "\n",
    "print(f\"selected classifier 6: lSVM_corr with accuracy {clf_corr['lSVM'].best_score_}\")\n",
    "print(f\"selected classifier 7: lg_corr with accuracy {clf_corr['lg'].best_score_}\")\n",
    "print(f\"selected classifier 8: XGB_corr with accuracy {clf_corr['XGB'].best_score_}\")\n",
    "print(f\"selected classifier 9: SVC_corr with accuracy {clf_corr['SVC'].best_score_}\")\n",
    "print(f\"selected classifier 10: nn_corr with accuracy {clf_corr['nn'].best_score_}\")\n",
    "\n",
    "print(f\"selected classifier 11: lSVM_corr_l with accuracy {clf_corr_l['lSVM'].best_score_}\")\n",
    "print(f\"selected classifier 12: lg_corr_l with accuracy {clf_corr_l['lg'].best_score_}\")\n",
    "print(f\"selected classifier 13: XGB_corr_l with accuracy {clf_corr_l['XGB'].best_score_}\")\n",
    "print(f\"selected classifier 14: SVC_corr_l with accuracy {clf_corr_l['SVC'].best_score_}\")\n",
    "print(f\"selected classifier 15: nn_corr_l with accuracy {clf_corr_l['nn'].best_score_}\")\n",
    "\n",
    "print(f\"selected classifier 16: lSVM_corr_r with accuracy {clf_corr_r['lSVM'].best_score_}\")\n",
    "print(f\"selected classifier 17: lg_corr_r with accuracy {clf_corr_r['lg'].best_score_}\")\n",
    "print(f\"selected classifier 18: XGB_corr_r with accuracy {clf_corr_r['XGB'].best_score_}\")\n",
    "print(f\"selected classifier 19: SVC_corr_r with accuracy {clf_corr_r['SVC'].best_score_}\")\n",
    "print(f\"selected classifier 20: nn_corr_r with accuracy {clf_corr_r['nn'].best_score_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the corresponding rfe object\n",
    "#clc15\n",
    "selected_rfe15 = load('./Final_Results/FS/Regular_minMaxNorm/rfetrain_svm.joblib')\n",
    "Xtest15 = XN[:, np.where(selected_rfe15.support_)[0]]\n",
    "\n",
    "# clc610\n",
    "selected_rfe610 = load('./Final_Results/FS/Regular_minMaxNorm/rfetrain_corr_svm.joblib')\n",
    "Xtest610 = XN[:, np.where(selected_rfe610.support_)[0]]\n",
    "\n",
    "# clc1115\n",
    "selected_rfe1115 = load('./Final_Results/FS/Regular_minMaxNorm/rfetrain_corr_l_svm.joblib')\n",
    "Xtest1115 = XN[:, np.where(selected_rfe1115.support_)[0]]\n",
    "\n",
    "# clc1620\n",
    "selected_rfe1620 = load('./Final_Results/FS/Regular_minMaxNorm/rfetrain_corr_r_svm.joblib')\n",
    "Xtest1620 = XN[:, np.where(selected_rfe1620.support_)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 16 artists>"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(np.where(selected_rfe15.support_))\n",
    "df_test.columns[np.where(selected_rfe15.support_)[0]],df_test.columns\n",
    "plt.barh(y=df_test.columns[np.where(selected_rfe15.support_)[0]], width=selected_clc2.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training dataset to train the current model using all training set\n",
    "# clc15\n",
    "Xtrain15 = np.load('./Final_Results/FS/Regular_minMaxNorm/Xtrain_svm.npy')\n",
    "\n",
    "# clc610\n",
    "Xtrain610 = np.load('./Final_Results/FS/Regular_minMaxNorm/Xtrain_corr_svm.npy')\n",
    "\n",
    "\n",
    "# clc1115\n",
    "Xtrain1115 = np.load('./Final_Results/FS/Regular_minMaxNorm/Xtrain_corr_l_svm.npy')\n",
    "\n",
    "# clc1620\n",
    "Xtrain1620 = np.load('./Final_Results/FS/Regular_minMaxNorm/Xtrain_corr_r_svm.npy')\n",
    "\n",
    "ytrain = np.load('./Final_Results/FS/Regular_minMaxNorm/ytrain_corr.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.58      0.64        36\n",
      "           1       0.59      0.71      0.65        31\n",
      "\n",
      "    accuracy                           0.64        67\n",
      "   macro avg       0.65      0.65      0.64        67\n",
      "weighted avg       0.65      0.64      0.64        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc1\n",
    "print(classification_report(df_test['labels'].values, selected_clc1.predict(Xtest15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.61      0.66        36\n",
      "           1       0.61      0.71      0.66        31\n",
      "\n",
      "    accuracy                           0.66        67\n",
      "   macro avg       0.66      0.66      0.66        67\n",
      "weighted avg       0.66      0.66      0.66        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc2\n",
    "print(classification_report(df_test['labels'].values, selected_clc2.predict(Xtest15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.56      0.61        36\n",
      "           1       0.57      0.68      0.62        31\n",
      "\n",
      "    accuracy                           0.61        67\n",
      "   macro avg       0.62      0.62      0.61        67\n",
      "weighted avg       0.62      0.61      0.61        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc3\n",
    "print(classification_report(df_test['labels'].values, selected_clc3.predict(Xtest15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.56      0.60        36\n",
      "           1       0.56      0.65      0.60        31\n",
      "\n",
      "    accuracy                           0.60        67\n",
      "   macro avg       0.60      0.60      0.60        67\n",
      "weighted avg       0.60      0.60      0.60        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc4\n",
    "print(classification_report(df_test['labels'].values, selected_clc4.predict(Xtest15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.58      0.62        36\n",
      "           1       0.57      0.65      0.61        31\n",
      "\n",
      "    accuracy                           0.61        67\n",
      "   macro avg       0.61      0.61      0.61        67\n",
      "weighted avg       0.62      0.61      0.61        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc5\n",
    "print(classification_report(df_test['labels'].values, selected_clc5.predict(Xtest15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.11      0.19        36\n",
      "           1       0.48      0.94      0.63        31\n",
      "\n",
      "    accuracy                           0.49        67\n",
      "   macro avg       0.57      0.52      0.41        67\n",
      "weighted avg       0.58      0.49      0.39        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc6\n",
    "print(classification_report(df_test['labels'].values, selected_clc6.predict(Xtest610)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.08      0.15        36\n",
      "           1       0.47      0.94      0.62        31\n",
      "\n",
      "    accuracy                           0.48        67\n",
      "   macro avg       0.53      0.51      0.38        67\n",
      "weighted avg       0.54      0.48      0.37        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc7\n",
    "print(classification_report(df_test['labels'].values, selected_clc7.predict(Xtest610)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.28      0.40        36\n",
      "           1       0.51      0.87      0.64        31\n",
      "\n",
      "    accuracy                           0.55        67\n",
      "   macro avg       0.61      0.57      0.52        67\n",
      "weighted avg       0.62      0.55      0.51        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc8\n",
    "print(classification_report(df_test['labels'].values, selected_clc8.predict(Xtest610)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.11      0.19        36\n",
      "           1       0.48      0.94      0.63        31\n",
      "\n",
      "    accuracy                           0.49        67\n",
      "   macro avg       0.57      0.52      0.41        67\n",
      "weighted avg       0.58      0.49      0.39        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc9\n",
    "print(classification_report(df_test['labels'].values, selected_clc9.predict(Xtest610)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.17      0.27        36\n",
      "           1       0.49      0.94      0.64        31\n",
      "\n",
      "    accuracy                           0.52        67\n",
      "   macro avg       0.62      0.55      0.46        67\n",
      "weighted avg       0.63      0.52      0.44        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc10\n",
    "print(classification_report(df_test['labels'].values, selected_clc10.predict(Xtest610)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.28      0.40        36\n",
      "           1       0.51      0.87      0.64        31\n",
      "\n",
      "    accuracy                           0.55        67\n",
      "   macro avg       0.61      0.57      0.52        67\n",
      "weighted avg       0.62      0.55      0.51        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc11\n",
    "print(classification_report(df_test['labels'].values, selected_clc11.predict(Xtest1115)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.31      0.43        36\n",
      "           1       0.52      0.87      0.65        31\n",
      "\n",
      "    accuracy                           0.57        67\n",
      "   macro avg       0.63      0.59      0.54        67\n",
      "weighted avg       0.63      0.57      0.53        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc12\n",
    "print(classification_report(df_test['labels'].values, selected_clc12.predict(Xtest1115)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.06      0.10        36\n",
      "           1       0.47      0.97      0.63        31\n",
      "\n",
      "    accuracy                           0.48        67\n",
      "   macro avg       0.57      0.51      0.37        67\n",
      "weighted avg       0.58      0.48      0.35        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc13\n",
    "print(classification_report(df_test['labels'].values, selected_clc13.predict(Xtest1115)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.61      0.57        36\n",
      "           1       0.46      0.39      0.42        31\n",
      "\n",
      "    accuracy                           0.51        67\n",
      "   macro avg       0.50      0.50      0.50        67\n",
      "weighted avg       0.50      0.51      0.50        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc14\n",
    "print(classification_report(df_test['labels'].values, selected_clc14.predict(Xtest1115)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.08      0.15        36\n",
      "           1       0.48      0.97      0.64        31\n",
      "\n",
      "    accuracy                           0.49        67\n",
      "   macro avg       0.61      0.53      0.39        67\n",
      "weighted avg       0.62      0.49      0.38        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc15\n",
    "print(classification_report(df_test['labels'].values, selected_clc15.predict(Xtest1115)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.47      0.54        36\n",
      "           1       0.53      0.68      0.59        31\n",
      "\n",
      "    accuracy                           0.57        67\n",
      "   macro avg       0.58      0.57      0.57        67\n",
      "weighted avg       0.58      0.57      0.56        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc16\n",
    "print(classification_report(df_test['labels'].values, selected_clc16.predict(Xtest1620)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.31      0.41        36\n",
      "           1       0.49      0.77      0.60        31\n",
      "\n",
      "    accuracy                           0.52        67\n",
      "   macro avg       0.55      0.54      0.50        67\n",
      "weighted avg       0.55      0.52      0.50        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc17\n",
    "print(classification_report(df_test['labels'].values, selected_clc17.predict(Xtest1620)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.33      0.45        36\n",
      "           1       0.52      0.84      0.64        31\n",
      "\n",
      "    accuracy                           0.57        67\n",
      "   macro avg       0.61      0.59      0.55        67\n",
      "weighted avg       0.62      0.57      0.54        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc18\n",
    "print(classification_report(df_test['labels'].values, selected_clc18.predict(Xtest1620)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.31      0.44        36\n",
      "           1       0.53      0.90      0.67        31\n",
      "\n",
      "    accuracy                           0.58        67\n",
      "   macro avg       0.66      0.60      0.55        67\n",
      "weighted avg       0.67      0.58      0.54        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc19\n",
    "print(classification_report(df_test['labels'].values, selected_clc19.predict(Xtest1620)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.11      0.20        36\n",
      "           1       0.48      0.97      0.65        31\n",
      "\n",
      "    accuracy                           0.51        67\n",
      "   macro avg       0.64      0.54      0.42        67\n",
      "weighted avg       0.65      0.51      0.40        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc20\n",
    "print(classification_report(df_test['labels'].values, selected_clc20.predict(Xtest1620)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:03:33] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample_bytree, gamma, min_child_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:03:38] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample_bytree, gamma, min_child_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:03:39] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample_bytree, gamma, min_child_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    }
   ],
   "source": [
    "selected_clc1 = selected_clc1.fit(Xtrain15, ytrain)\n",
    "selected_clc2 = selected_clc2.fit(Xtrain15, ytrain)\n",
    "selected_clc3 = selected_clc3.fit(Xtrain15, ytrain)\n",
    "selected_clc4 = selected_clc4.fit(Xtrain15, ytrain)\n",
    "selected_clc5 = selected_clc5.fit(Xtrain15, ytrain)\n",
    "selected_clc6 = selected_clc6.fit(Xtrain610, ytrain)\n",
    "selected_clc7 = selected_clc7.fit(Xtrain610, ytrain)\n",
    "selected_clc8 = selected_clc8.fit(Xtrain610, ytrain)\n",
    "selected_clc9 = selected_clc9.fit(Xtrain610, ytrain)\n",
    "selected_clc10 = selected_clc10.fit(Xtrain610, ytrain)\n",
    "selected_clc11 = selected_clc11.fit(Xtrain1115, ytrain)\n",
    "selected_clc12 = selected_clc12.fit(Xtrain1115, ytrain)\n",
    "selected_clc13 = selected_clc13.fit(Xtrain1115, ytrain)\n",
    "selected_clc14 = selected_clc14.fit(Xtrain1115, ytrain)\n",
    "selected_clc15 = selected_clc15.fit(Xtrain1115, ytrain)\n",
    "selected_clc16 = selected_clc16.fit(Xtrain1620, ytrain)\n",
    "selected_clc17 = selected_clc17.fit(Xtrain1620, ytrain)\n",
    "selected_clc18 = selected_clc18.fit(Xtrain1620, ytrain)\n",
    "selected_clc19 = selected_clc19.fit(Xtrain1620, ytrain)\n",
    "selected_clc20 = selected_clc20.fit(Xtrain1620, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.58      0.64        36\n",
      "           1       0.59      0.71      0.65        31\n",
      "\n",
      "    accuracy                           0.64        67\n",
      "   macro avg       0.65      0.65      0.64        67\n",
      "weighted avg       0.65      0.64      0.64        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc1\n",
    "print(classification_report(df_test['labels'].values, selected_clc1.predict(Xtest15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.61      0.66        36\n",
      "           1       0.61      0.71      0.66        31\n",
      "\n",
      "    accuracy                           0.66        67\n",
      "   macro avg       0.66      0.66      0.66        67\n",
      "weighted avg       0.66      0.66      0.66        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc2\n",
    "print(classification_report(df_test['labels'].values, selected_clc2.predict(Xtest15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.53      0.58        36\n",
      "           1       0.55      0.68      0.61        31\n",
      "\n",
      "    accuracy                           0.60        67\n",
      "   macro avg       0.60      0.60      0.60        67\n",
      "weighted avg       0.61      0.60      0.60        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc3\n",
    "print(classification_report(df_test['labels'].values, selected_clc3.predict(Xtest15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.56      0.60        36\n",
      "           1       0.56      0.65      0.60        31\n",
      "\n",
      "    accuracy                           0.60        67\n",
      "   macro avg       0.60      0.60      0.60        67\n",
      "weighted avg       0.60      0.60      0.60        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc4\n",
    "print(classification_report(df_test['labels'].values, selected_clc4.predict(Xtest15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.50      0.58        36\n",
      "           1       0.56      0.74      0.64        31\n",
      "\n",
      "    accuracy                           0.61        67\n",
      "   macro avg       0.63      0.62      0.61        67\n",
      "weighted avg       0.63      0.61      0.61        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc5\n",
    "print(classification_report(df_test['labels'].values, selected_clc5.predict(Xtest15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.11      0.19        36\n",
      "           1       0.48      0.94      0.63        31\n",
      "\n",
      "    accuracy                           0.49        67\n",
      "   macro avg       0.57      0.52      0.41        67\n",
      "weighted avg       0.58      0.49      0.39        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc6\n",
    "print(classification_report(df_test['labels'].values, selected_clc6.predict(Xtest610)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.08      0.15        36\n",
      "           1       0.47      0.94      0.62        31\n",
      "\n",
      "    accuracy                           0.48        67\n",
      "   macro avg       0.53      0.51      0.38        67\n",
      "weighted avg       0.54      0.48      0.37        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc7\n",
    "print(classification_report(df_test['labels'].values, selected_clc7.predict(Xtest610)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.58      0.61        36\n",
      "           1       0.56      0.61      0.58        31\n",
      "\n",
      "    accuracy                           0.60        67\n",
      "   macro avg       0.60      0.60      0.60        67\n",
      "weighted avg       0.60      0.60      0.60        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc8\n",
    "print(classification_report(df_test['labels'].values, selected_clc8.predict(Xtest610)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.11      0.19        36\n",
      "           1       0.48      0.94      0.63        31\n",
      "\n",
      "    accuracy                           0.49        67\n",
      "   macro avg       0.57      0.52      0.41        67\n",
      "weighted avg       0.58      0.49      0.39        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc9\n",
    "print(classification_report(df_test['labels'].values, selected_clc9.predict(Xtest610)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.11      0.19        36\n",
      "           1       0.48      0.94      0.63        31\n",
      "\n",
      "    accuracy                           0.49        67\n",
      "   macro avg       0.57      0.52      0.41        67\n",
      "weighted avg       0.58      0.49      0.39        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc10\n",
    "print(classification_report(df_test['labels'].values, selected_clc10.predict(Xtest610)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.28      0.40        36\n",
      "           1       0.51      0.87      0.64        31\n",
      "\n",
      "    accuracy                           0.55        67\n",
      "   macro avg       0.61      0.57      0.52        67\n",
      "weighted avg       0.62      0.55      0.51        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc11\n",
    "print(classification_report(df_test['labels'].values, selected_clc11.predict(Xtest1115)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.31      0.43        36\n",
      "           1       0.52      0.87      0.65        31\n",
      "\n",
      "    accuracy                           0.57        67\n",
      "   macro avg       0.63      0.59      0.54        67\n",
      "weighted avg       0.63      0.57      0.53        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc12\n",
    "print(classification_report(df_test['labels'].values, selected_clc12.predict(Xtest1115)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        36\n",
      "           1       0.46      1.00      0.63        31\n",
      "\n",
      "    accuracy                           0.46        67\n",
      "   macro avg       0.23      0.50      0.32        67\n",
      "weighted avg       0.21      0.46      0.29        67\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# clc13\n",
    "print(classification_report(df_test['labels'].values, selected_clc13.predict(Xtest1115)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.61      0.57        36\n",
      "           1       0.46      0.39      0.42        31\n",
      "\n",
      "    accuracy                           0.51        67\n",
      "   macro avg       0.50      0.50      0.50        67\n",
      "weighted avg       0.50      0.51      0.50        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc14\n",
    "print(classification_report(df_test['labels'].values, selected_clc14.predict(Xtest1115)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.03      0.05        36\n",
      "           1       0.47      1.00      0.64        31\n",
      "\n",
      "    accuracy                           0.48        67\n",
      "   macro avg       0.73      0.51      0.35        67\n",
      "weighted avg       0.75      0.48      0.32        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc15\n",
    "print(classification_report(df_test['labels'].values, selected_clc15.predict(Xtest1115)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.47      0.54        36\n",
      "           1       0.53      0.68      0.59        31\n",
      "\n",
      "    accuracy                           0.57        67\n",
      "   macro avg       0.58      0.57      0.57        67\n",
      "weighted avg       0.58      0.57      0.56        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc16\n",
    "print(classification_report(df_test['labels'].values, selected_clc16.predict(Xtest1620)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.31      0.41        36\n",
      "           1       0.49      0.77      0.60        31\n",
      "\n",
      "    accuracy                           0.52        67\n",
      "   macro avg       0.55      0.54      0.50        67\n",
      "weighted avg       0.55      0.52      0.50        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc17\n",
    "print(classification_report(df_test['labels'].values, selected_clc17.predict(Xtest1620)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.17      0.25        36\n",
      "           1       0.45      0.81      0.58        31\n",
      "\n",
      "    accuracy                           0.46        67\n",
      "   macro avg       0.48      0.49      0.42        67\n",
      "weighted avg       0.48      0.46      0.40        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc18\n",
    "print(classification_report(df_test['labels'].values, selected_clc18.predict(Xtest1620)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.31      0.44        36\n",
      "           1       0.53      0.90      0.67        31\n",
      "\n",
      "    accuracy                           0.58        67\n",
      "   macro avg       0.66      0.60      0.55        67\n",
      "weighted avg       0.67      0.58      0.54        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clc19\n",
    "print(classification_report(df_test['labels'].values, selected_clc19.predict(Xtest1620)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        36\n",
      "           1       0.46      1.00      0.63        31\n",
      "\n",
      "    accuracy                           0.46        67\n",
      "   macro avg       0.23      0.50      0.32        67\n",
      "weighted avg       0.21      0.46      0.29        67\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# clc20\n",
    "print(classification_report(df_test['labels'].values, selected_clc20.predict(Xtest1620)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './Final_Results/ML/minmaxreg/clf__rf_train_corr.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-307-37cdf8845841>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./Final_Results/ML/minmaxreg/clf__rf_train.joblib'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclf_corr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./Final_Results/ML/minmaxreg/clf__rf_train_corr.joblib'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mclf_corr_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./Final_Results/ML/minmaxreg/clf__rf_train_corr_l.joblib'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mclf_corr_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./Final_Results/ML/minmaxreg/clf__rf_train_corr_r.joblib'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\joblib\\numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    595\u001b[0m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 597\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    598\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0m_read_fileobject\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_basestring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Final_Results/ML/minmaxreg/clf__rf_train_corr.joblib'"
     ]
    }
   ],
   "source": [
    "clf = load('./Final_Results/ML/minmaxreg/clf__rf_train.joblib')\n",
    "clf_corr = load('./Final_Results/ML/minmaxreg/clf__rf_train_corr.joblib')\n",
    "clf_corr_l = load('./Final_Results/ML/minmaxreg/clf__rf_train_corr_l.joblib')\n",
    "clf_corr_r = load('./Final_Results/ML/minmaxreg/clf__rf_train_corr_r.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf__rf_train\n",
      "0.5964124293785311\n",
      "0.5017514124293785\n",
      "0.5947175141242939\n",
      "0.5879943502824859\n",
      "0.5203389830508474\n",
      "0.5965254237288135\n",
      "0.5393220338983051\n",
      "0.5536440677966101\n",
      "0000000000000000000000000000000000000000000\n",
      "clf__rf_train_corr\n",
      "0.5877966101694916\n",
      "0.5572033898305084\n",
      "0.609774011299435\n",
      "0.5811864406779661\n",
      "0.5352824858757061\n",
      "0.606186440677966\n",
      "0.5626553672316386\n",
      "0.5925423728813559\n",
      "0000000000000000000000000000000000000000000\n",
      "clf__rf_train_corr_l\n",
      "0.5642655367231638\n",
      "0.5248870056497175\n",
      "0.567683615819209\n",
      "0.5876836158192089\n",
      "0.5503954802259887\n",
      "0.599180790960452\n",
      "0.5592655367231638\n",
      "0.5877683615819208\n",
      "0000000000000000000000000000000000000000000\n",
      "clf__rf_train_corr_r\n",
      "0.5796045197740114\n",
      "0.532768361581921\n",
      "0.5881073446327683\n",
      "0.5964971751412429\n",
      "0.5287005649717513\n",
      "0.5947175141242939\n",
      "0.5727401129943503\n",
      "0.5846610169491526\n"
     ]
    }
   ],
   "source": [
    "print(\"clf__rf_train\")\n",
    "print(clf['lSVM'].best_score_)\n",
    "print(clf['pagg'].best_score_)\n",
    "print(clf['lg'].best_score_)\n",
    "print(clf['XGB'].best_score_)\n",
    "print(clf['GNB'].best_score_)\n",
    "print(clf['SVC'].best_score_)\n",
    "print(clf['Rf'].best_score_)\n",
    "print(clf['nn'].best_score_)\n",
    "print(\"0000000000000000000000000000000000000000000\")\n",
    "print(\"clf__rf_train_corr\")\n",
    "print(clf_corr['lSVM'].best_score_)\n",
    "print(clf_corr['pagg'].best_score_)\n",
    "print(clf_corr['lg'].best_score_)\n",
    "print(clf_corr['XGB'].best_score_)\n",
    "print(clf_corr['GNB'].best_score_)\n",
    "print(clf_corr['SVC'].best_score_)\n",
    "print(clf_corr['Rf'].best_score_)\n",
    "print(clf_corr['nn'].best_score_)\n",
    "print(\"0000000000000000000000000000000000000000000\")\n",
    "print(\"clf__rf_train_corr_l\")\n",
    "print(clf_corr_l['lSVM'].best_score_)\n",
    "print(clf_corr_l['pagg'].best_score_)\n",
    "print(clf_corr_l['lg'].best_score_)\n",
    "print(clf_corr_l['XGB'].best_score_)\n",
    "print(clf_corr_l['GNB'].best_score_)\n",
    "print(clf_corr_l['SVC'].best_score_)\n",
    "print(clf_corr_l['Rf'].best_score_)\n",
    "print(clf_corr_l['nn'].best_score_)\n",
    "print(\"0000000000000000000000000000000000000000000\")\n",
    "print(\"clf__rf_train_corr_r\")\n",
    "print(clf_corr_r['lSVM'].best_score_)\n",
    "print(clf_corr_r['pagg'].best_score_)\n",
    "print(clf_corr_r['lg'].best_score_)\n",
    "print(clf_corr_r['XGB'].best_score_)\n",
    "print(clf_corr_r['GNB'].best_score_)\n",
    "print(clf_corr_r['SVC'].best_score_)\n",
    "print(clf_corr_r['Rf'].best_score_)\n",
    "print(clf_corr_r['nn'].best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected classifier 1: lg_corr with accuracy 0.609774011299435\n",
      "selected classifier 2: SVC_corr with accuracy 0.606186440677966\n"
     ]
    }
   ],
   "source": [
    "selected_clc1 = clf_corr['lg'].best_estimator_\n",
    "selected_clc2 = clf_corr['SVC'].best_estimator_\n",
    "print(f\"selected classifier 1: lg_corr with accuracy {clf_corr['lg'].best_score_}\")\n",
    "print(f\"selected classifier 2: SVC_corr with accuracy {clf_corr['SVC'].best_score_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67, 545)\n",
      "0    36\n",
      "1    31\n",
      "Name: labels, dtype: int64\n",
      "baseline score:  0.5373134328358209\n"
     ]
    }
   ],
   "source": [
    "# Load test dataset\n",
    "df_test = pd.read_csv('./Final_Results/INITIAL_SPLIT/test_fullbrain.csv', index_col=0)\n",
    "print(df_test.shape)\n",
    "print(df_test['labels'].value_counts())\n",
    "\n",
    "print('baseline score: ',36/(31+36))\n",
    "XN = mynormalize(df_test, allfeats=False)\n",
    "\n",
    "# Load the corresponding rfe object\n",
    "#clc1,2\n",
    "selected_rfe1 = load('./Final_Results/FS/Normalize_allMorphFeats/rfetrain_corr_rf.joblib')\n",
    "Xtest1 = XN[:, np.where(selected_rfe1.support_)[0]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training dataset to train the current model using all training set\n",
    "# clc1\n",
    "Xtrain1 = np.load('./Final_Results/FS/Normalize_allMorphFeats/Xtrain_corr_rf.npy')\n",
    "ytrain = np.load('./Final_Results/FS/Normalize_allMorphFeats/ytrain_corr.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      1.00      0.70        36\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.54        67\n",
      "   macro avg       0.27      0.50      0.35        67\n",
      "weighted avg       0.29      0.54      0.38        67\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# clc1\n",
    "print(classification_report(df_test['labels'].values, selected_clc1.predict(Xtest1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        36\n",
      "           1       0.46      1.00      0.63        31\n",
      "\n",
      "    accuracy                           0.46        67\n",
      "   macro avg       0.23      0.50      0.32        67\n",
      "weighted avg       0.21      0.46      0.29        67\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# clc2\n",
    "print(classification_report(df_test['labels'].values, selected_clc2.predict(Xtest1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "selected_clc1 = selected_clc1.fit(Xtrain1, ytrain)\n",
    "selected_clc2 = selected_clc2.fit(Xtrain1, ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      1.00      0.70        36\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.54        67\n",
      "   macro avg       0.27      0.50      0.35        67\n",
      "weighted avg       0.29      0.54      0.38        67\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# clc1\n",
    "print(classification_report(df_test['labels'].values, selected_clc1.predict(Xtest1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        36\n",
      "           1       0.46      1.00      0.63        31\n",
      "\n",
      "    accuracy                           0.46        67\n",
      "   macro avg       0.23      0.50      0.32        67\n",
      "weighted avg       0.21      0.46      0.29        67\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# clc2\n",
    "print(classification_report(df_test['labels'].values, selected_clc2.predict(Xtest1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "untitled",
   "language": "python",
   "name": "untitled"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
